<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>prom.metrics &mdash; Prom v0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Prom
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../src/prom.html">prom package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src/prom.conformity_scores.html">prom.conformity_scores package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src/prom.control_risk.html">prom.control_risk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src/prom.estimator.html">prom.estimator package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../src/prom.regression.html">prom.regression package</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Thread Coarsening API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/thread/Deeptune_utils.html">Deeptune_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/thread/Magni_utils.html">Magni_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/thread/Thread_Deep.html">Thread_Deep module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/thread/Thread_i2v.html">Thread_i2v module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/thread/Thread_magni.html">Thread_magni module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Loop Tiling API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Deeptune_utils.html">Deeptune_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Loop_de.html">Loop_de module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Loop_ma.html">Loop_ma module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Loop_SVM.html">Loop_SVM module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Loop_thread_sensitive.html">Loop_thread_sensitive module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Magni_utils.html">Magni_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/Ml_utils.html">Ml_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/Loop/prom_util_sensitive.html">prom_util_sensitive module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device Mapping API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.datasets.html">compy.datasets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.graphs.html">compy.models.graphs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.graphs.tf.cell.html">compy.models.graphs.tf.cell package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.graphs.tf.layer.html">compy.models.graphs.tf.layer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.graphs.tf.html">compy.models.graphs.tf package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.html">compy.models package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.models.seqs.html">compy.models.seqs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.representations.extractors.html">compy.representations.extractors package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/compy.representations.html">compy.representations package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/copy_pytorch_geom_model_sec.html">copy_pytorch_geom_model_sec module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/DevM_i2v.html">DevM_i2v module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/DevM_Programl.html">DevM_Programl module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/devmap_exploration.html">devmap_exploration module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/look.html">look module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/Mapie.html">Mapie module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/modules.html">DeviceM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/pytorch_geom_model_pchange.html">pytorch_geom_model_pchange module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/DeviceM/setup.html">setup module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tensor Tuning API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/autotvm_x.html">autotvm_x module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/bert_large.html">bert_large module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/bert_med.html">bert_med module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/bert_tiny.html">bert_tiny module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/common.html">common module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/dump_network_info.html">dump_network_info module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/dump_programs.html">dump_programs module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/estimate_network_latency.html">estimate_network_latency module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/eval_model_on_dataset.html">eval_model_on_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/lightgbm_bayesian_hyperparameter_opt.html">lightgbm_bayesian_hyperparameter_opt module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/make_dataset.html">make_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/measure_programs.html">measure_programs module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/modules.html">scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/mtl_tlp_make_dataset.html">mtl_tlp_make_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/mtl_tlp_train.html">mtl_tlp_train module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/network2measure_records.html">network2measure_records module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/nni_hyperparameter_opt.html">nni_hyperparameter_opt module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/print_all_tasks.html">print_all_tasks module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/print_programs.html">print_programs module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/search.html">search module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/sensitive.html">sensitive module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tlp_eval.html">tlp_eval module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tlp_fine_tune.html">tlp_fine_tune module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tlp_make_dataset.html">tlp_make_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tlp_make_dataset_bert.html">tlp_make_dataset_bert module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tlp_preprocess_dataset_gpu.html">tlp_preprocess_dataset_gpu module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/train_model.html">train_model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/train_tlp.html">train_tlp module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/tlp/tune_network.html">tune_network module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Bug Detection API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/BugD/model.html">model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/BugD/preprocess.html">preprocess module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/BugD/VD_codebert.html">VD_codebert module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../case_study/BugD/VD_vulde.html">VD_vulde module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Prom</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">prom.metrics</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for prom.metrics</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">column_or_1d</span>

<span class="kn">from</span> <span class="nn">._machine_precision</span> <span class="kn">import</span> <span class="n">EPSILON</span>
<span class="kn">from</span> <span class="nn">._typing</span> <span class="kn">import</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">NDArray</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="p">(</span><span class="n">calc_bins</span><span class="p">,</span> <span class="n">check_alpha</span><span class="p">,</span> <span class="n">check_array_inf</span><span class="p">,</span> <span class="n">check_array_nan</span><span class="p">,</span>
                    <span class="n">check_array_shape_classification</span><span class="p">,</span>
                    <span class="n">check_array_shape_regression</span><span class="p">,</span> <span class="n">check_arrays_length</span><span class="p">,</span>
                    <span class="n">check_binary_zero_one</span><span class="p">,</span> <span class="n">check_lower_upper_bounds</span><span class="p">,</span>
                    <span class="n">check_nb_intervals_sizes</span><span class="p">,</span> <span class="n">check_nb_sets_sizes</span><span class="p">,</span>
                    <span class="n">check_number_bins</span><span class="p">,</span> <span class="n">check_split_strategy</span><span class="p">)</span>


<div class="viewcode-block" id="regression_coverage_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_coverage_score">[docs]</a><span class="k">def</span> <span class="nf">regression_coverage_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_low</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_up</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Effective coverage score obtained by the prediction intervals.</span>

<span class="sd">    The effective coverage is obtained by estimating the fraction</span>
<span class="sd">    of true labels that lie within the prediction intervals.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: ArrayLike of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_pred_low: ArrayLike of shape (n_samples,)</span>
<span class="sd">        Lower bound of prediction intervals.</span>
<span class="sd">    y_pred_up: ArrayLike of shape (n_samples,)</span>
<span class="sd">        Upper bound of prediction intervals.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Effective coverage obtained by the prediction intervals.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import regression_coverage_score</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([5, 7.5, 9.5, 10.5, 12.5])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_low = np.array([4, 6, 9, 8.5, 10.5])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_up = np.array([6, 9, 10, 12.5, 12])</span>
<span class="sd">    &gt;&gt;&gt; print(regression_coverage_score(y_true, y_pred_low, y_pred_up))</span>
<span class="sd">    0.8</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_pred_low</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">))</span>
    <span class="n">y_pred_up</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">))</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_low</span><span class="p">,</span> <span class="n">y_pred_up</span><span class="p">)</span>
    <span class="n">check_lower_upper_bounds</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_low</span><span class="p">,</span> <span class="n">y_pred_up</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">)</span>

    <span class="n">coverage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="p">((</span><span class="n">y_pred_low</span> <span class="o">&lt;=</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred_up</span> <span class="o">&gt;=</span> <span class="n">y_true</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">coverage</span><span class="p">)</span></div>


<div class="viewcode-block" id="classification_coverage_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.classification_coverage_score">[docs]</a><span class="k">def</span> <span class="nf">classification_coverage_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_set</span><span class="p">:</span> <span class="n">ArrayLike</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Effective coverage score obtained by the prediction sets.</span>

<span class="sd">    The effective coverage is obtained by estimating the fraction</span>
<span class="sd">    of true labels that lie within the prediction sets.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: ArrayLike of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_pred_set: ArrayLike of shape (n_samples, n_class)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Effective coverage obtained by the prediction sets.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import classification_coverage_score</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([3, 3, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_set = np.array([</span>
<span class="sd">    ...     [False, False,  True,  True],</span>
<span class="sd">    ...     [False,  True, False,  True],</span>
<span class="sd">    ...     [False,  True,  True, False],</span>
<span class="sd">    ...     [False, False,  True,  True],</span>
<span class="sd">    ...     [False,  True, False,  True]</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; print(classification_coverage_score(y_true, y_pred_set))</span>
<span class="sd">    0.8</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_pred_set</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
        <span class="n">NDArray</span><span class="p">,</span>
        <span class="n">check_array</span><span class="p">(</span>
            <span class="n">y_pred_set</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;bool&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>

    <span class="n">coverage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span>
        <span class="n">y_pred_set</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">coverage</span><span class="p">)</span></div>


<div class="viewcode-block" id="regression_mean_width_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_mean_width_score">[docs]</a><span class="k">def</span> <span class="nf">regression_mean_width_score</span><span class="p">(</span>
    <span class="n">y_pred_low</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_up</span><span class="p">:</span> <span class="n">ArrayLike</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Effective mean width score obtained by the prediction intervals.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_pred_low: ArrayLike of shape (n_samples,)</span>
<span class="sd">        Lower bound of prediction intervals.</span>
<span class="sd">    y_pred_up: ArrayLike of shape (n_samples,)</span>
<span class="sd">        Upper bound of prediction intervals.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Effective mean width of the prediction intervals.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import regression_mean_width_score</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_pred_low = np.array([4, 6, 9, 8.5, 10.5])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_up = np.array([6, 9, 10, 12.5, 12])</span>
<span class="sd">    &gt;&gt;&gt; print(regression_mean_width_score(y_pred_low, y_pred_up))</span>
<span class="sd">    2.3</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_pred_low</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">))</span>
    <span class="n">y_pred_up</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">))</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">,</span> <span class="n">y_pred_up</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">)</span>

    <span class="n">mean_width</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_pred_up</span> <span class="o">-</span> <span class="n">y_pred_low</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">mean_width</span><span class="p">)</span></div>


<div class="viewcode-block" id="classification_mean_width_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.classification_mean_width_score">[docs]</a><span class="k">def</span> <span class="nf">classification_mean_width_score</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mean width of prediction set output by</span>
<span class="sd">    :class:`~mapie.classification.MapieClassifier`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_pred_set: ArrayLike of shape (n_samples, n_class)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Mean width of the prediction set.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import classification_mean_width_score</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_pred_set = np.array([</span>
<span class="sd">    ...     [False, False,  True,  True],</span>
<span class="sd">    ...     [False,  True, False,  True],</span>
<span class="sd">    ...     [False,  True,  True, False],</span>
<span class="sd">    ...     [False, False,  True,  True],</span>
<span class="sd">    ...     [False,  True, False,  True]</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; print(classification_mean_width_score(y_pred_set))</span>
<span class="sd">    2.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_pred_set</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
        <span class="n">NDArray</span><span class="p">,</span>
        <span class="n">check_array</span><span class="p">(</span>
            <span class="n">y_pred_set</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;bool&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">mean_width</span> <span class="o">=</span> <span class="n">y_pred_set</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">mean_width</span><span class="p">)</span></div>


<div class="viewcode-block" id="expected_calibration_error"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.expected_calibration_error">[docs]</a><span class="k">def</span> <span class="nf">expected_calibration_error</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_scores</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">split_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The expected calibration error, which is the difference between</span>
<span class="sd">    the confidence scores and accuracy per bin [1].</span>

<span class="sd">    [1] Naeini, Mahdi Pakdaman, Gregory Cooper, and Milos Hauskrecht.</span>
<span class="sd">    &quot;Obtaining well calibrated probabilities using bayesian binning.&quot;</span>
<span class="sd">    Twenty-Ninth AAAI Conference on Artificial Intelligence. 2015.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: ArrayLike of shape (n_samples,)</span>
<span class="sd">        The target values for the calibrator.</span>
<span class="sd">    y_score: ArrayLike of shape (n_samples,) or (n_samples, n_classes)</span>
<span class="sd">        The predictions scores.</span>
<span class="sd">    num_bins: int</span>
<span class="sd">        Number of bins to make the split in the y_score. The allowed</span>
<span class="sd">        values are num_bins above 0.</span>
<span class="sd">    split_strategy: str</span>
<span class="sd">        The way of splitting the predictions into different bins.</span>
<span class="sd">        The allowed split strategies are &quot;uniform&quot;, &quot;quantile&quot; and</span>
<span class="sd">        &quot;array split&quot;.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The score of ECE (Expected Calibration Error).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">split_strategy</span> <span class="o">=</span> <span class="n">check_split_strategy</span><span class="p">(</span><span class="n">split_strategy</span><span class="p">)</span>
    <span class="n">num_bins</span> <span class="o">=</span> <span class="n">check_number_bins</span><span class="p">(</span><span class="n">num_bins</span><span class="p">)</span>
    <span class="n">y_true_</span> <span class="o">=</span> <span class="n">check_binary_zero_one</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_scores</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true_</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true_</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true_</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">y_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
            <span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">y_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_scores</span><span class="p">))</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">bin_accs</span><span class="p">,</span> <span class="n">bin_confs</span><span class="p">,</span> <span class="n">bin_sizes</span> <span class="o">=</span> <span class="n">calc_bins</span><span class="p">(</span>
        <span class="n">y_true_</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">,</span> <span class="n">split_strategy</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bin_sizes</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">bin_accs</span> <span class="o">-</span> <span class="n">bin_confs</span><span class="p">)),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bin_sizes</span><span class="p">)</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="top_label_ece"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.top_label_ece">[docs]</a><span class="k">def</span> <span class="nf">top_label_ece</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_scores</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_score_arg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">split_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Top-Label ECE which is a method adapted to fit the</span>
<span class="sd">    ECE to a Top-Label setting [2].</span>

<span class="sd">    [2] Gupta, Chirag, and Aaditya K. Ramdas.</span>
<span class="sd">    &quot;Top-label calibration and multiclass-to-binary reductions.&quot;</span>
<span class="sd">    arXiv preprint arXiv:2107.08353 (2021).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: ArrayLike of shape (n_samples,)</span>
<span class="sd">        The target values for the calibrator.</span>
<span class="sd">    y_scores: ArrayLike of shape (n_samples, n_classes)</span>
<span class="sd">    or (n_samples,)</span>
<span class="sd">        The predictions scores, either the maximum score and the</span>
<span class="sd">        argmax needs to be inputted or in the form of the prediction</span>
<span class="sd">        probabilities.</span>
<span class="sd">    y_score_arg: Optional[ArrayLike] of shape (n_samples,)</span>
<span class="sd">        If only the maximum is provided in the y_scores, the argmax must</span>
<span class="sd">        be provided here. This is optional and could be directly infered</span>
<span class="sd">        from the y_scores.</span>
<span class="sd">    num_bins: int</span>
<span class="sd">        Number of bins to make the split in the y_score. The allowed</span>
<span class="sd">        values are num_bins above 0.</span>
<span class="sd">    split_strategy: str</span>
<span class="sd">        The way of splitting the predictions into different bins.</span>
<span class="sd">        The allowed split strategies are &quot;uniform&quot;, &quot;quantile&quot; and</span>
<span class="sd">        &quot;array split&quot;.</span>
<span class="sd">    classes: ArrayLike of shape (n_samples,)</span>
<span class="sd">        The different classes, in order of the indices that would be</span>
<span class="sd">        present in a pred_proba.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The ECE score adapted in the top label setting.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_scores</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_score_arg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_score_arg</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score_arg</span><span class="p">)</span>
        <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score_arg</span><span class="p">)</span>
        <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score_arg</span><span class="p">)</span>
        <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">,</span> <span class="n">y_score_arg</span><span class="p">)</span>

    <span class="n">ece</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
    <span class="n">split_strategy</span> <span class="o">=</span> <span class="n">check_split_strategy</span><span class="p">(</span><span class="n">split_strategy</span><span class="p">)</span>
    <span class="n">num_bins</span> <span class="o">=</span> <span class="n">check_number_bins</span><span class="p">(</span><span class="n">num_bins</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">y_score_arg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
            <span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">y_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y_score_arg</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
                <span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanargmax</span><span class="p">(</span><span class="n">y_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
            <span class="n">y_score_arg</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
                <span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nanargmax</span><span class="p">(</span><span class="n">y_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_score</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_scores</span><span class="p">))</span>
        <span class="n">y_score_arg</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score_arg</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_score_arg</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
        <span class="n">label_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="n">y_score_arg</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_true_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">label_ind</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">ece</span> <span class="o">+=</span> <span class="n">expected_calibration_error</span><span class="p">(</span>
            <span class="n">y_true_</span><span class="p">,</span>
            <span class="n">y_scores</span><span class="o">=</span><span class="n">y_score</span><span class="p">[</span><span class="n">label_ind</span><span class="p">],</span>
            <span class="n">num_bins</span><span class="o">=</span><span class="n">num_bins</span><span class="p">,</span>
            <span class="n">split_strategy</span><span class="o">=</span><span class="n">split_strategy</span>
        <span class="p">)</span>
    <span class="n">ece</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ece</span></div>


<div class="viewcode-block" id="regression_coverage_score_v2"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_coverage_score_v2">[docs]</a><span class="k">def</span> <span class="nf">regression_coverage_score_v2</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_intervals</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Effective coverage score obtained by the prediction intervals.</span>

<span class="sd">    The effective coverage is obtained by estimating the fraction</span>
<span class="sd">    of true labels that lie within the prediction intervals.</span>

<span class="sd">    It is different from ``regression_coverage_score`` because it uses</span>
<span class="sd">    directly the output of ``predict`` method and can compute the</span>
<span class="sd">    coverage for each alpha.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples, n_alpha) or (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_intervals: NDArray of shape (n_samples, 2, n_alpha)</span>
<span class="sd">        Lower and upper bound of prediction intervals</span>
<span class="sd">        with different alpha risks.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha,)</span>
<span class="sd">        Effective coverage obtained by the prediction intervals.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>

    <span class="n">y_intervals</span> <span class="o">=</span> <span class="n">check_array_shape_regression</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">coverages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y_true</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y_true</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">coverages</span></div>


<div class="viewcode-block" id="classification_coverage_score_v2"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.classification_coverage_score_v2">[docs]</a><span class="k">def</span> <span class="nf">classification_coverage_score_v2</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_pred_set</span><span class="p">:</span> <span class="n">NDArray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Effective coverage score obtained by the prediction sets.</span>

<span class="sd">    The effective coverage is obtained by estimating the fraction</span>
<span class="sd">    of true labels that lie within the prediction sets.</span>

<span class="sd">    It is different from ``classification_coverage_score`` because it uses</span>
<span class="sd">    directly the output of ``predict`` method and can compute the</span>
<span class="sd">    coverage for each alpha.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples, n_alpha) or (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_pred_set: NDArray of shape (n_samples, n_class, n_alpha)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha,)</span>
<span class="sd">        Effective coverage obtained by the prediction sets.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>

    <span class="n">y_pred_set</span> <span class="o">=</span> <span class="n">check_array_shape_classification</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">coverage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">coverage</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>


<div class="viewcode-block" id="regression_ssc"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_ssc">[docs]</a><span class="k">def</span> <span class="nf">regression_ssc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_intervals</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Size-Stratified Coverage metrics proposed in [3] that is</span>
<span class="sd">    the conditional coverage conditioned by the size of the intervals.</span>
<span class="sd">    The intervals are ranked by their size (ascending) and then divided into</span>
<span class="sd">    num_bins groups: one value of coverage by groups is computed.</span>

<span class="sd">    Warning: This metric should be used only with non constant intervals</span>
<span class="sd">    (intervals of different sizes), with constant intervals the result</span>
<span class="sd">    may be misinterpreted.</span>

<span class="sd">    [3] Angelopoulos, A. N., &amp; Bates, S. (2021).</span>
<span class="sd">    A gentle introduction to conformal prediction and</span>
<span class="sd">    distribution-free uncertainty quantification.</span>
<span class="sd">    arXiv preprint arXiv:2107.07511.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_intervals: NDArray of shape (n_samples, 2, n_alpha) or (n_samples, 2)</span>
<span class="sd">        Prediction intervals given by booleans of labels.</span>
<span class="sd">    num_bins: int n</span>
<span class="sd">        Number of groups. Should be less than the number of different</span>
<span class="sd">        interval widths.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha, num_bins)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import regression_ssc</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([5, 7.5, 9.5])</span>
<span class="sd">    &gt;&gt;&gt; y_intervals = np.array([</span>
<span class="sd">    ... [4, 6],</span>
<span class="sd">    ... [6.0, 9.0],</span>
<span class="sd">    ... [9, 10.0]</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; print(regression_ssc(y_true, y_intervals, num_bins=2))</span>
<span class="sd">    [[1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_intervals</span> <span class="o">=</span> <span class="n">check_array_shape_regression</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_number_bins</span><span class="p">(</span><span class="n">num_bins</span><span class="p">)</span>
    <span class="n">widths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">check_nb_intervals_sizes</span><span class="p">(</span><span class="n">widths</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">)</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>

    <span class="n">indexes_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">widths</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">indexes_bybins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">indexes_sorted</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">coverages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y_intervals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">num_bins</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indexes_bybins</span><span class="p">):</span>
        <span class="n">intervals_binned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
            <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">indexes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">indexes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">coverages</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">regression_coverage_score_v2</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">indexes</span><span class="p">],</span>
                                                       <span class="n">intervals_binned</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">coverages</span></div>


<div class="viewcode-block" id="regression_ssc_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_ssc_score">[docs]</a><span class="k">def</span> <span class="nf">regression_ssc_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_intervals</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Aggregate by the minimum for each alpha the Size-Stratified Coverage [3]:</span>
<span class="sd">    returns the maximum violation of the conditional coverage</span>
<span class="sd">    (with the groups defined).</span>

<span class="sd">    Warning: This metric should be used only with non constant intervals</span>
<span class="sd">    (intervals of different sizes), with constant intervals the result</span>
<span class="sd">    may be misinterpreted.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_intervals: NDArray of shape (n_samples, 2, n_alpha) or (n_samples, 2)</span>
<span class="sd">        Prediction intervals given by booleans of labels.</span>
<span class="sd">    num_bins: int n</span>
<span class="sd">        Number of groups. Should be less than the number of different</span>
<span class="sd">        interval widths.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha,)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import regression_ssc</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([5, 7.5, 9.5])</span>
<span class="sd">    &gt;&gt;&gt; y_intervals = np.array([</span>
<span class="sd">    ... [[4, 4], [6, 7.5]],</span>
<span class="sd">    ... [[6.0, 8], [9.0, 10]],</span>
<span class="sd">    ... [[9, 9], [10.0, 10.0]]</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; print(regression_ssc_score(y_true, y_intervals, num_bins=2))</span>
<span class="sd">    [1.  0.5]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">regression_ssc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="classification_ssc"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.classification_ssc">[docs]</a><span class="k">def</span> <span class="nf">classification_ssc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_pred_set</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Size-Stratified Coverage metrics proposed in [3] that is</span>
<span class="sd">    the conditional coverage conditioned by the size of the predictions sets.</span>
<span class="sd">    The sets are ranked by their size (ascending) and then divided into</span>
<span class="sd">    num_bins groups: one value of coverage by groups is computed.</span>

<span class="sd">    [3] Angelopoulos, A. N., &amp; Bates, S. (2021).</span>
<span class="sd">    A gentle introduction to conformal prediction and</span>
<span class="sd">    distribution-free uncertainty quantification.</span>
<span class="sd">    arXiv preprint arXiv:2107.07511.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_pred_set: NDArray of shape (n_samples, n_class, n_alpha)</span>
<span class="sd">    or (n_samples, n_class)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>
<span class="sd">    num_bins: int or None</span>
<span class="sd">        Number of groups. If None, one value of coverage by possible</span>
<span class="sd">        size of sets (n_classes +1) is computed. Should be less than the</span>
<span class="sd">        number of different set sizes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha, num_bins)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import classification_ssc</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = y_true_class = np.array([3, 3, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_set = np.array([</span>
<span class="sd">    ...    [True, True, True, True],</span>
<span class="sd">    ...    [False, True, False, True],</span>
<span class="sd">    ...    [True, True, True, False],</span>
<span class="sd">    ...    [False, False, True, True],</span>
<span class="sd">    ...    [True, True, False, True]])</span>
<span class="sd">    &gt;&gt;&gt; print(classification_ssc(y_true, y_pred_set, num_bins=2))</span>
<span class="sd">    [[1.         0.66666667]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_pred_set</span> <span class="o">=</span> <span class="n">check_array_shape_classification</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>

    <span class="n">sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="n">y_pred_set</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">num_bins</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">check_nb_sets_sizes</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">)</span>
        <span class="n">check_number_bins</span><span class="p">(</span><span class="n">num_bins</span><span class="p">)</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_bins</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">digitized_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>
    <span class="n">coverages</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y_pred_set</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">bins</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_pred_set</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
        <span class="n">indexes_bybins</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">digitized_sizes</span><span class="p">[:,</span> <span class="n">alpha</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indexes_bybins</span><span class="p">):</span>
            <span class="n">coverages</span><span class="p">[</span><span class="n">alpha</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">classification_coverage_score_v2</span><span class="p">(</span>
                <span class="n">y_true</span><span class="p">[</span><span class="n">indexes</span><span class="p">],</span>
                <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span>
                    <span class="n">y_pred_set</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">alpha</span><span class="p">],</span>
                    <span class="n">indexes</span><span class="p">,</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">coverages</span></div>


<div class="viewcode-block" id="classification_ssc_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.classification_ssc_score">[docs]</a><span class="k">def</span> <span class="nf">classification_ssc_score</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_pred_set</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Aggregate by the minimum for each alpha the Size-Stratified Coverage [3]:</span>
<span class="sd">    returns the maximum violation of the conditional coverage</span>
<span class="sd">    (with the groups defined).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_pred_set: NDArray of shape (n_samples, n_class, n_alpha)</span>
<span class="sd">    or (n_samples, n_class)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>
<span class="sd">    num_bins: int or None</span>
<span class="sd">        Number of groups. If None, one value of coverage by possible</span>
<span class="sd">        size of sets (n_classes +1) is computed. Should be less than</span>
<span class="sd">        the number of different set sizes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha,)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import classification_ssc_score</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = y_true_class = np.array([3, 3, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; y_pred_set = np.array([</span>
<span class="sd">    ...    [True, True, True, True],</span>
<span class="sd">    ...    [False, True, False, True],</span>
<span class="sd">    ...    [True, True, True, False],</span>
<span class="sd">    ...    [False, False, True, True],</span>
<span class="sd">    ...    [True, True, False, True]])</span>
<span class="sd">    &gt;&gt;&gt; print(classification_ssc_score(y_true, y_pred_set, num_bins=2))</span>
<span class="sd">    [0.66666667]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_pred_set</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmin</span><span class="p">(</span><span class="n">classification_ssc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_set</span><span class="p">,</span> <span class="n">num_bins</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_gaussian_kernel</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the gaussian kernel of x. (Used in hsic function)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: NDArray</span>
<span class="sd">        The values from which to compute the gaussian kernel.</span>
<span class="sd">    kernel_size: int</span>
<span class="sd">        The variance (sigma), this coefficient controls the width of the curve.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span> \
        <span class="o">+</span> <span class="n">norm_x</span> <span class="o">+</span> <span class="n">norm_x</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="n">kernel_size</span><span class="p">)</span>


<div class="viewcode-block" id="hsic"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.hsic">[docs]</a><span class="k">def</span> <span class="nf">hsic</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_intervals</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">kernel_sizes</span><span class="p">:</span> <span class="n">ArrayLike</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the square root of the hsic coefficient. HSIC is Hilbert-Schmidt</span>
<span class="sd">    independence criterion that is a correlation measure. Here we use it as</span>
<span class="sd">    proposed in [4], to compute the correlation between the indicator of</span>
<span class="sd">    coverage and the interval size.</span>

<span class="sd">    If hsic is 0, the two variables (the indicator of coverage and the</span>
<span class="sd">    interval size) are independant.</span>

<span class="sd">    Warning: This metric should be used only with non constant intervals</span>
<span class="sd">    (intervals of different sizes), with constant intervals the result</span>
<span class="sd">    may be misinterpreted.</span>

<span class="sd">    [4] Feldman, S., Bates, S., &amp; Romano, Y. (2021).</span>
<span class="sd">    Improving conditional coverage via orthogonal quantile regression.</span>
<span class="sd">    Advances in Neural Information Processing Systems, 34, 2060-2071.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: NDArray of shape (n_samples,)</span>
<span class="sd">        True labels.</span>
<span class="sd">    y_intervals: NDArray of shape (n_samples, 2, n_alpha) or (n_samples, 2)</span>
<span class="sd">        Prediction sets given by booleans of labels.</span>
<span class="sd">    kernel_sizes: ArrayLike of size (2,)</span>
<span class="sd">        The variance (sigma) for each variable (the indicator of coverage and</span>
<span class="sd">        the interval size), this coefficient controls the width of the curve.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray of shape (n_alpha,)</span>
<span class="sd">        One hsic correlation coefficient by alpha.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If kernel_sizes has a length different from 2</span>
<span class="sd">        and if it has negative or null values.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import hsic</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([9.5, 10.5, 12.5])</span>
<span class="sd">    &gt;&gt;&gt; y_intervals = np.array([</span>
<span class="sd">    ... [[9, 9], [10.0, 10.0]],</span>
<span class="sd">    ... [[8.5, 9], [12.5, 12]],</span>
<span class="sd">    ... [[10.5, 10.5], [12.0, 12]]</span>
<span class="sd">    ... ])</span>
<span class="sd">    &gt;&gt;&gt; print(hsic(y_true, y_intervals))</span>
<span class="sd">    [0.31787614 0.2962914 ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_intervals</span> <span class="o">=</span> <span class="n">check_array_shape_regression</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">)</span>

    <span class="n">kernel_sizes</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">kernel_sizes</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;kernel_sizes should be an ArrayLike of length 2&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">kernel_sizes</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;kernel_size should be positive&quot;</span>
        <span class="p">)</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">n_alpha</span> <span class="o">=</span> <span class="n">y_intervals</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">y_true_per_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">(</span><span class="n">n_alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
    <span class="n">widths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>
    <span class="n">cov_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">(</span>
            <span class="p">((</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;=</span> <span class="n">y_true_per_alpha</span><span class="p">)</span> <span class="o">&amp;</span>
             <span class="p">(</span><span class="n">y_intervals</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&gt;=</span> <span class="n">y_true_per_alpha</span><span class="p">))</span>
        <span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>

    <span class="n">k_mat</span> <span class="o">=</span> <span class="n">_gaussian_kernel</span><span class="p">(</span><span class="n">widths</span><span class="p">,</span> <span class="n">kernel_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">l_mat</span> <span class="o">=</span> <span class="n">_gaussian_kernel</span><span class="p">(</span><span class="n">cov_ind</span><span class="p">,</span> <span class="n">kernel_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">h_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
    <span class="n">hsic_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">l_mat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_mat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">k_mat</span><span class="p">,</span> <span class="n">h_mat</span><span class="p">)))</span>
    <span class="n">hsic_mat</span> <span class="o">/=</span> <span class="p">((</span><span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">coef_hsic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">hsic_mat</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">coef_hsic</span></div>


<div class="viewcode-block" id="coverage_width_based"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.coverage_width_based">[docs]</a><span class="k">def</span> <span class="nf">coverage_width_based</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_low</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred_up</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">eta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Coverage Width-based Criterion (CWC) obtained by the prediction intervals.</span>

<span class="sd">    The effective coverage score is a criterion used to evaluate the quality</span>
<span class="sd">    of prediction intervals (PIs) based on their coverage and width.</span>

<span class="sd">    Khosravi, Abbas, Saeid Nahavandi, and Doug Creighton.</span>
<span class="sd">    &quot;Construction of optimal prediction intervals for load forecasting</span>
<span class="sd">    problems.&quot;</span>
<span class="sd">    IEEE Transactions on Power Systems 25.3 (2010): 1496-1503.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    Coverage score : float</span>
<span class="sd">        Prediction interval coverage probability (Coverage score), which is</span>
<span class="sd">        the estimated fraction of true labels that lie within the prediction</span>
<span class="sd">        intervals.</span>
<span class="sd">    Mean Width Score : float</span>
<span class="sd">        Prediction interval normalized average width (Mean Width Score),</span>
<span class="sd">        calculated as the average width of the prediction intervals.</span>
<span class="sd">    eta : int</span>
<span class="sd">        A user-defined parameter that balances the contributions of</span>
<span class="sd">        Mean Width Score and Coverage score in the CWC calculation.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        A user-defined parameter representing the designed confidence level of</span>
<span class="sd">        the PI.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Effective coverage score (CWC) obtained by the prediction intervals.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The effective coverage score (CWC) is calculated using the following</span>
<span class="sd">    formula:</span>
<span class="sd">    CWC = (1 - Mean Width Score) * exp(-eta * (Coverage score - (1-alpha))**2)</span>

<span class="sd">    The CWC penalizes under- and overcoverage in the same way and summarizes</span>
<span class="sd">    the quality of the prediction intervals in a single value.</span>

<span class="sd">    High Eta (Large Positive Value):</span>

<span class="sd">    When eta is a high positive value, it will strongly</span>
<span class="sd">    emphasize the contribution of (1-Mean Width Score). This means that the</span>
<span class="sd">    algorithm will prioritize reducing the average width of the prediction</span>
<span class="sd">    intervals (Mean Width Score) over achieving a high coverage probability</span>
<span class="sd">    (Coverage score). The exponential term np.exp(-eta*(Coverage score -</span>
<span class="sd">    (1-alpha))**2) will have a sharp decline as Coverage score deviates</span>
<span class="sd">    from (1-alpha). So, achieving a high Coverage score becomes less important</span>
<span class="sd">    compared to minimizing Mean Width Score.</span>
<span class="sd">    The impact will be narrower prediction intervals on average, which may</span>
<span class="sd">    result in more precise but less conservative predictions.</span>

<span class="sd">    Low Eta (Small Positive Value):</span>

<span class="sd">    When eta is a low positive value, it will still</span>
<span class="sd">    prioritize reducing the average width of the prediction intervals</span>
<span class="sd">    (Mean Width Score) but with less emphasis compared to higher</span>
<span class="sd">    eta values.</span>
<span class="sd">    The exponential term will be less steep, meaning that deviations of</span>
<span class="sd">    Coverage score from (1-alpha) will have a moderate impact.</span>
<span class="sd">    You&#39;ll get a balance between prediction precision and coverage, but the</span>
<span class="sd">    exact balance will depend on the specific value of eta.</span>

<span class="sd">    Negative Eta (Any Negative Value):</span>

<span class="sd">    When eta is negative, it will have a different effect on the formula.</span>
<span class="sd">    Negative values of eta will cause the exponential term</span>
<span class="sd">    np.exp(-eta*(Coverage score - (1-alpha))**2) to become larger as</span>
<span class="sd">    Coverage score deviates from (1-alpha). This means that</span>
<span class="sd">    a negative eta prioritizes achieving a high coverage probability</span>
<span class="sd">    (Coverage score) over minimizing Mean Width Score.</span>
<span class="sd">    In this case, the algorithm will aim to produce wider prediction intervals</span>
<span class="sd">    to ensure a higher likelihood of capturing the true values within those</span>
<span class="sd">    intervals, even if it sacrifices precision.</span>
<span class="sd">    Negative eta values might be used in scenarios where avoiding errors or</span>
<span class="sd">    outliers is critical.</span>

<span class="sd">    Null Eta (Eta = 0):</span>

<span class="sd">    Specifically, when eta is zero, the CWC score becomes equal to</span>
<span class="sd">    (1 - Mean Width Score), which is equivalent to</span>
<span class="sd">    (1 - average width of the prediction intervals).</span>
<span class="sd">    Therefore, in this case, the CWC score is primarily based on the size of</span>
<span class="sd">    the prediction interval.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([5, 7.5, 9.5, 10.5, 12.5])</span>
<span class="sd">    &gt;&gt;&gt; y_preds_low = np.array([4, 6, 9, 8.5, 10.5])</span>
<span class="sd">    &gt;&gt;&gt; y_preds_up = np.array([6, 9, 10, 12.5, 12])</span>
<span class="sd">    &gt;&gt;&gt; eta = 0.01</span>
<span class="sd">    &gt;&gt;&gt; alpha = 0.1</span>
<span class="sd">    &gt;&gt;&gt; cwb = coverage_width_based(y_true, y_preds_low, y_preds_up, eta, alpha)</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(cwb ,2))</span>
<span class="sd">    0.69</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="n">y_pred_low</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">))</span>
    <span class="n">y_pred_up</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">))</span>

    <span class="n">check_alpha</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span>

    <span class="n">coverage_score</span> <span class="o">=</span> <span class="n">regression_coverage_score</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_pred_low</span><span class="p">,</span>
        <span class="n">y_pred_up</span>
    <span class="p">)</span>
    <span class="n">mean_width</span> <span class="o">=</span> <span class="n">regression_mean_width_score</span><span class="p">(</span>
        <span class="n">y_pred_low</span><span class="p">,</span>
        <span class="n">y_pred_up</span>
    <span class="p">)</span>
    <span class="n">ref_length</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span>
        <span class="nb">float</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span>
        <span class="nb">float</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
    <span class="p">)</span>
    <span class="n">avg_length</span> <span class="o">=</span> <span class="n">mean_width</span> <span class="o">/</span> <span class="n">ref_length</span>

    <span class="n">cwc</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">avg_length</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">eta</span><span class="o">*</span><span class="p">(</span><span class="n">coverage_score</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">cwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="add_jitter"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.add_jitter">[docs]</a><span class="k">def</span> <span class="nf">add_jitter</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">noise_amplitude</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add a tiny normal distributed perturbation to an array x.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : NDArray</span>
<span class="sd">        The array to jitter.</span>

<span class="sd">    noise_amplitude : float, optional</span>
<span class="sd">        The tiny relative noise amplitude to add, by default 1e-8.</span>

<span class="sd">    random_state: Optional[Union[int, RandomState]]</span>
<span class="sd">        Pseudo random number generator state used for random sampling.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray</span>
<span class="sd">        The array x jittered.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import add_jitter</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([0, 1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; res = add_jitter(x, random_state=1)</span>
<span class="sd">    &gt;&gt;&gt; res</span>
<span class="sd">    array([0.        , 0.99999999, 1.99999999, 2.99999997, 4.00000003])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">random_state_np</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">noise_amplitude</span> <span class="o">*</span> <span class="n">random_state_np</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">x_jittered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">noise</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_jittered</span></div>


<div class="viewcode-block" id="sort_xy_by_y"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.sort_xy_by_y">[docs]</a><span class="k">def</span> <span class="nf">sort_xy_by_y</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sort two arrays x and y according to y values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : NDArray of size (n_samples,)</span>
<span class="sd">        The array to sort according to y.</span>
<span class="sd">    y : NDArray of size (n_samples,)</span>
<span class="sd">        The array to sort.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[NDArray, NDArray]</span>
<span class="sd">        Both arrays sorted.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import sort_xy_by_y</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([1, 2, 3, 4, 5])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([5, 4, 3, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; x_sorted, y_sorted = sort_xy_by_y(x, y)</span>
<span class="sd">    &gt;&gt;&gt; print(x_sorted)</span>
<span class="sd">    [4 5 3 2 1]</span>
<span class="sd">    &gt;&gt;&gt; print(y_sorted)</span>
<span class="sd">    [1 2 3 4 5]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">sort_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">x_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
    <span class="n">y_sorted</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">sort_index</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_sorted</span><span class="p">,</span> <span class="n">y_sorted</span></div>


<div class="viewcode-block" id="cumulative_differences"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.cumulative_differences">[docs]</a><span class="k">def</span> <span class="nf">cumulative_differences</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
    <span class="n">noise_amplitude</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the cumulative difference between y_true and y_score, both ordered</span>
<span class="sd">    according to y_scores array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of size (n_samples,)</span>
<span class="sd">        An array of ground truths.</span>

<span class="sd">    y_score : NDArray of size (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    noise_amplitude : float, optional</span>
<span class="sd">        The tiny relative noise amplitude to add, by default 1e-8.</span>

<span class="sd">    random_state: Optional[Union[int, RandomState]]</span>
<span class="sd">        Pseudo random number generator state used for random sampling.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    NDArray</span>
<span class="sd">        The mean cumulative difference between y_true and y_score.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Arrieta-Ibarra I, Gujral P, Tannen J, Tygert M, Xu C.</span>
<span class="sd">    Metrics of calibration for probabilistic predictions.</span>
<span class="sd">    The Journal of Machine Learning Research.</span>
<span class="sd">    2022 Jan 1;23(1):15886-940.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import cumulative_differences</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([1, 0, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.7, 0.3, 0.6])</span>
<span class="sd">    &gt;&gt;&gt; cum_diff = cumulative_differences(y_true, y_score)</span>
<span class="sd">    &gt;&gt;&gt; print(len(cum_diff))</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(np.max(cum_diff) &lt;= 1)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; print(np.min(cum_diff) &gt;= -1)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; cum_diff</span>
<span class="sd">    array([-0.1, -0.3, -0.2])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_score_jittered</span> <span class="o">=</span> <span class="n">add_jitter</span><span class="p">(</span>
        <span class="n">y_score</span><span class="p">,</span>
        <span class="n">noise_amplitude</span><span class="o">=</span><span class="n">noise_amplitude</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
    <span class="p">)</span>
    <span class="n">y_true_sorted</span><span class="p">,</span> <span class="n">y_score_sorted</span> <span class="o">=</span> <span class="n">sort_xy_by_y</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score_jittered</span><span class="p">)</span>
    <span class="n">cumulative_differences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">y_true_sorted</span> <span class="o">-</span> <span class="n">y_score_sorted</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="k">return</span> <span class="n">cumulative_differences</span></div>


<div class="viewcode-block" id="length_scale"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.length_scale">[docs]</a><span class="k">def</span> <span class="nf">length_scale</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the mean square root of the sum  of s * (1 - s).</span>
<span class="sd">    This is basically the standard deviation of the</span>
<span class="sd">    cumulative differences.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    s : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The length_scale array.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Arrieta-Ibarra I, Gujral P, Tannen J, Tygert M, Xu C.</span>
<span class="sd">    Metrics of calibration for probabilistic predictions.</span>
<span class="sd">    The Journal of Machine Learning Research.</span>
<span class="sd">    2022 Jan 1;23(1):15886-940.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import length_scale</span>
<span class="sd">    &gt;&gt;&gt; s = np.array([0, 0, 0.4, 0.3, 0.8])</span>
<span class="sd">    &gt;&gt;&gt; res = length_scale(s)</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(res, 2))</span>
<span class="sd">    0.16</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="p">)))</span><span class="o">/</span><span class="n">n</span>
    <span class="k">return</span> <span class="n">length_scale</span></div>


<div class="viewcode-block" id="kolmogorov_smirnov_statistic"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kolmogorov_smirnov_statistic">[docs]</a><span class="k">def</span> <span class="nf">kolmogorov_smirnov_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Kolmogorov-smirnov&#39;s statistic for calibration test.</span>
<span class="sd">    Also called ECCE-MAD</span>
<span class="sd">    (Estimated Cumulative Calibration Errors - Maximum Absolute Deviation).</span>
<span class="sd">    The closer to zero, the better the scores are calibrated.</span>
<span class="sd">    Indeed, if the scores are perfectly calibrated,</span>
<span class="sd">    the cumulative differences between ``y_true`` and ``y_score``</span>
<span class="sd">    should share the same properties of a standard Brownian motion</span>
<span class="sd">    asymptotically.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores..</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Kolmogorov-smirnov&#39;s statistic.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Arrieta-Ibarra I, Gujral P, Tannen J, Tygert M, Xu C.</span>
<span class="sd">    Metrics of calibration for probabilistic predictions.</span>
<span class="sd">    The Journal of Machine Learning Research.</span>
<span class="sd">    2022 Jan 1;23(1):15886-940.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kolmogorov_smirnov_statistic</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.1, 0.9, 0.21, 0.9, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(kolmogorov_smirnov_statistic(y_true, y_score), 3))</span>
<span class="sd">    0.978</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">cum_diff</span> <span class="o">=</span> <span class="n">cumulative_differences</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">length_scale</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">ks_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cum_diff</span><span class="p">))</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="k">return</span> <span class="n">ks_stat</span></div>


<div class="viewcode-block" id="kolmogorov_smirnov_cdf"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kolmogorov_smirnov_cdf">[docs]</a><span class="k">def</span> <span class="nf">kolmogorov_smirnov_cdf</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Kolmogorov-smirnov cumulative distribution</span>
<span class="sd">    function (CDF) for the float x.</span>
<span class="sd">    This is interpreted as the CDF of the maximum absolute value</span>
<span class="sd">    of the standard Brownian motion over the unit interval [0, 1].</span>
<span class="sd">    The function is approximated by its power series, truncated so as to hit</span>
<span class="sd">    machine precision error.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : float</span>
<span class="sd">        The float x to compute the cumulative distribution function on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The Kolmogorov-smirnov cumulative distribution function.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Tygert M.</span>
<span class="sd">    Calibration of P-values for calibration and for deviation</span>
<span class="sd">    of a subpopulation from the full population.</span>
<span class="sd">    arXiv preprint arXiv:2202.00100.</span>
<span class="sd">    2022 Jan 31.</span>

<span class="sd">    D. A. Darling. A. J. F. Siegert.</span>
<span class="sd">    The First Passage Problem for a Continuous Markov Process.</span>
<span class="sd">    Ann. Math. Statist. 24 (4) 624 - 639, December,</span>
<span class="sd">    1953.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kolmogorov_smirnov_cdf</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(kolmogorov_smirnov_cdf(1), 4))</span>
<span class="sd">    0.3708</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
        <span class="mf">0.5</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">4</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">EPSILON</span><span class="p">)))</span>
    <span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">kmax</span><span class="p">)):</span>
        <span class="n">kplus</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="n">k</span> <span class="o">/</span> <span class="n">kplus</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">kplus</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">c</span> <span class="o">*=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
    <span class="k">return</span> <span class="n">c</span></div>


<div class="viewcode-block" id="kolmogorov_smirnov_p_value"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kolmogorov_smirnov_p_value">[docs]</a><span class="k">def</span> <span class="nf">kolmogorov_smirnov_p_value</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Kolmogorov Smirnov p-value.</span>
<span class="sd">    Deduced from the corresponding statistic and CDF.</span>
<span class="sd">    It represents the probability of the observed statistic</span>
<span class="sd">    under the null hypothesis of perfect calibration.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The Kolmogorov Smirnov p-value.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Tygert M.</span>
<span class="sd">    Calibration of P-values for calibration and for deviation</span>
<span class="sd">    of a subpopulation from the full population.</span>
<span class="sd">    arXiv preprint arXiv:2202.00100.</span>
<span class="sd">    2022 Jan 31.</span>

<span class="sd">    D. A. Darling. A. J. F. Siegert.</span>
<span class="sd">    The First Passage Problem for a Continuous Markov Process.</span>
<span class="sd">    Ann. Math. Statist. 24 (4) 624 - 639, December,</span>
<span class="sd">    1953.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kolmogorov_smirnov_p_value</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([1, 0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.8, 0.3, 0.5, 0.5, 0.7, 0.1])</span>
<span class="sd">    &gt;&gt;&gt; ks_p_value = kolmogorov_smirnov_p_value(y_true, y_score)</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(ks_p_value, 4))</span>
<span class="sd">    0.7857</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">ks_stat</span> <span class="o">=</span> <span class="n">kolmogorov_smirnov_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">ks_p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">kolmogorov_smirnov_cdf</span><span class="p">(</span><span class="n">ks_stat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ks_p_value</span></div>


<div class="viewcode-block" id="kuiper_statistic"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kuiper_statistic">[docs]</a><span class="k">def</span> <span class="nf">kuiper_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Kuiper&#39;s statistic for calibration test.</span>
<span class="sd">    Also called ECCE-R (Estimated Cumulative Calibration Errors - Range).</span>
<span class="sd">    The closer to zero, the better the scores are calibrated.</span>
<span class="sd">    Indeed, if the scores are perfectly calibrated,</span>
<span class="sd">    the cumulative differences between ``y_true`` and ``y_score``</span>
<span class="sd">    should share the same properties of a standard Brownian motion</span>
<span class="sd">    asymptotically.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Kuiper&#39;s statistic.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Arrieta-Ibarra I, Gujral P, Tannen J, Tygert M, Xu C.</span>
<span class="sd">    Metrics of calibration for probabilistic predictions.</span>
<span class="sd">    The Journal of Machine Learning Research.</span>
<span class="sd">    2022 Jan 1;23(1):15886-940.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kuiper_statistic</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.1, 0.9, 0.21, 0.9, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(kuiper_statistic(y_true, y_score), 3))</span>
<span class="sd">    0.857</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">cum_diff</span> <span class="o">=</span> <span class="n">cumulative_differences</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">length_scale</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">ku_stat</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">cum_diff</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">cum_diff</span><span class="p">))</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="k">return</span> <span class="n">ku_stat</span></div>


<div class="viewcode-block" id="kuiper_cdf"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kuiper_cdf">[docs]</a><span class="k">def</span> <span class="nf">kuiper_cdf</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Kuiper cumulative distribution function (CDF) for the float x.</span>
<span class="sd">    This is interpreted as the CDF of the range</span>
<span class="sd">    of the standard Brownian motion over the unit interval [0, 1].</span>
<span class="sd">    The function is approximated by its power series, truncated so as to hit</span>
<span class="sd">    machine precision error.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : float</span>
<span class="sd">        The float x to compute the cumulative distribution function.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The Kuiper cumulative distribution function.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Tygert M.</span>
<span class="sd">    Calibration of P-values for calibration and for deviation</span>
<span class="sd">    of a subpopulation from the full population.</span>
<span class="sd">    arXiv preprint arXiv:2202.00100.</span>
<span class="sd">    2022 Jan 31.</span>

<span class="sd">    William Feller.</span>
<span class="sd">    The Asymptotic Distribution of the Range of Sums of</span>
<span class="sd">    Independent Random Variables.</span>
<span class="sd">    Ann. Math. Statist. 22 (3) 427 - 432</span>
<span class="sd">    September, 1951.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kuiper_cdf</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(kuiper_cdf(1), 4))</span>
<span class="sd">    0.0634</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="mf">0.5</span> <span class="o">+</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                    <span class="mi">4</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">EPSILON</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">kmax</span><span class="p">)):</span>
        <span class="n">kplus</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">c</span> <span class="o">+=</span> <span class="p">(</span>
            <span class="p">(</span><span class="mi">8</span> <span class="o">/</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">kplus</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span>
            <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">kplus</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span></div>


<div class="viewcode-block" id="kuiper_p_value"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.kuiper_p_value">[docs]</a><span class="k">def</span> <span class="nf">kuiper_p_value</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Kuiper statistic p-value.</span>
<span class="sd">    Deduced from the corresponding statistic and CDF.</span>
<span class="sd">    It represents the probability of the observed statistic</span>
<span class="sd">    under the null hypothesis of perfect calibration.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The Kuiper p-value.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Tygert M.</span>
<span class="sd">    Calibration of P-values for calibration and for deviation</span>
<span class="sd">    of a subpopulation from the full population.</span>
<span class="sd">    arXiv preprint arXiv:2202.00100.</span>
<span class="sd">    2022 Jan 31.</span>

<span class="sd">    William Feller.</span>
<span class="sd">    The Asymptotic Distribution of the Range of Sums of</span>
<span class="sd">    Independent Random Variables.</span>
<span class="sd">    Ann. Math. Statist. 22 (3) 427 - 432</span>
<span class="sd">    September, 1951.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import kuiper_p_value</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([1, 0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.8, 0.3, 0.5, 0.5, 0.7, 0.1])</span>
<span class="sd">    &gt;&gt;&gt; ku_p_value = kuiper_p_value(y_true, y_score)</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(ku_p_value, 4))</span>
<span class="sd">    0.9684</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">ku_stat</span> <span class="o">=</span> <span class="n">kuiper_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">ku_p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">kuiper_cdf</span><span class="p">(</span><span class="n">ku_stat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ku_p_value</span></div>


<div class="viewcode-block" id="spiegelhalter_statistic"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.spiegelhalter_statistic">[docs]</a><span class="k">def</span> <span class="nf">spiegelhalter_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Spiegelhalter&#39;s statistic for calibration test.</span>
<span class="sd">    The closer to zero, the better the scores are calibrated.</span>
<span class="sd">    Indeed, if the scores are perfectly calibrated,</span>
<span class="sd">    the Brier score simplifies to an expression whose expectancy</span>
<span class="sd">    and variance are easy to compute. The statistic is no more that</span>
<span class="sd">    a z-score on this normalized expression.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Spiegelhalter&#39;s statistic.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Spiegelhalter DJ.</span>
<span class="sd">    Probabilistic prediction in patient management and clinical trials.</span>
<span class="sd">    Statistics in medicine.</span>
<span class="sd">    1986 Sep;5(5):421-33.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import spiegelhalter_statistic</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.1, 0.9, 0.21, 0.9, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(spiegelhalter_statistic(y_true, y_score), 3))</span>
<span class="sd">    -0.757</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>

    <span class="n">y_true</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_score</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_score</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_score</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_score</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">sp_stat</span> <span class="o">=</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>
    <span class="k">return</span> <span class="n">sp_stat</span></div>


<div class="viewcode-block" id="spiegelhalter_p_value"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.spiegelhalter_p_value">[docs]</a><span class="k">def</span> <span class="nf">spiegelhalter_p_value</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">y_score</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Spiegelhalter statistic p-value.</span>
<span class="sd">    Deduced from the corresponding statistic and CDF,</span>
<span class="sd">    which is no more than the normal distribution.</span>
<span class="sd">    It represents the probability of the observed statistic</span>
<span class="sd">    under the null hypothesis of perfect calibration.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of ground truth.</span>

<span class="sd">    y_score : NDArray of shape (n_samples,)</span>
<span class="sd">        An array of scores.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The Spiegelhalter statistic p_value.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Spiegelhalter DJ.</span>
<span class="sd">    Probabilistic prediction in patient management and clinical trials.</span>
<span class="sd">    Statistics in medicine.</span>
<span class="sd">    1986 Sep;5(5):421-33.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from mapie.metrics import spiegelhalter_p_value</span>
<span class="sd">    &gt;&gt;&gt; y_true = np.array([1, 0, 1, 0, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; y_score = np.array([0.8, 0.3, 0.5, 0.5, 0.7, 0.1])</span>
<span class="sd">    &gt;&gt;&gt; sp_p_value = spiegelhalter_p_value(y_true, y_score)</span>
<span class="sd">    &gt;&gt;&gt; print(np.round(sp_p_value, 4))</span>
<span class="sd">    0.8486</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">check_array_nan</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">check_array_inf</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
    <span class="n">sp_stat</span> <span class="o">=</span> <span class="n">spiegelhalter_statistic</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">sp_p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">sp_stat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sp_p_value</span></div>


<div class="viewcode-block" id="regression_mwi_score"><a class="viewcode-back" href="../../src/prom.html#prom.metrics.regression_mwi_score">[docs]</a><span class="k">def</span> <span class="nf">regression_mwi_score</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
        <span class="n">y_pis</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Winkler score, proposed by Winkler (1972), is a measure used to</span>
<span class="sd">    evaluate prediction intervals, combining the length of the interval</span>
<span class="sd">    with a penalty that increases proportionally to the distance of an</span>
<span class="sd">    observation outside the interval.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_true: ArrayLike of shape (n_samples,)</span>
<span class="sd">        Ground truth values</span>
<span class="sd">    y_pis: ArrayLike of shape (n_samples, 2, 1)</span>
<span class="sd">        Lower and upper bounds of prediction intervals</span>
<span class="sd">        output from a MAPIE regressor</span>
<span class="sd">    alpha: float</span>
<span class="sd">        The value of alpha</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The mean Winkler interval score</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Robert L. Winkler</span>
<span class="sd">    &quot;A Decision-Theoretic Approach to Interval Estimation&quot;,</span>
<span class="sd">    Journal of the American Statistical Association,</span>
<span class="sd">    volume 67, pages 187-191 (1972)</span>
<span class="sd">    (https://doi.org/10.1080/01621459.1972.10481224)</span>
<span class="sd">    [2] Tilmann Gneiting and Adrian E Raftery</span>
<span class="sd">    &quot;Strictly Proper Scoring Rules, Prediction, and Estimation&quot;,</span>
<span class="sd">    Journal of the American Statistical Association,</span>
<span class="sd">    volume 102, pages 359-378 (2007)</span>
<span class="sd">    (https://doi.org/10.1198/016214506000001437) (Section 6.2)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Undo any possible quantile crossing</span>
    <span class="n">y_pred_low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">y_pis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_pis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">y_pred_up</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">y_pis</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_pis</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="n">check_arrays_length</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_low</span><span class="p">,</span> <span class="n">y_pred_up</span><span class="p">)</span>

    <span class="c1"># Checking for NaN and inf values</span>
    <span class="k">for</span> <span class="n">array</span> <span class="ow">in</span> <span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_low</span><span class="p">,</span> <span class="n">y_pred_up</span><span class="p">):</span>
        <span class="n">check_array_nan</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
        <span class="n">check_array_inf</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

    <span class="n">width</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred_up</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred_low</span><span class="p">)</span>
    <span class="n">error_above</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred_up</span><span class="p">)[</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="n">y_pred_up</span><span class="p">])</span>
    <span class="n">error_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_pred_low</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)[</span><span class="n">y_true</span> <span class="o">&lt;</span> <span class="n">y_pred_low</span><span class="p">])</span>
    <span class="n">total_error</span> <span class="o">=</span> <span class="n">error_above</span> <span class="o">+</span> <span class="n">error_below</span>
    <span class="n">mwi</span> <span class="o">=</span> <span class="p">(</span><span class="n">width</span> <span class="o">+</span> <span class="n">total_error</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mwi</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, _.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>