<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>prom.estimator.estimator &mdash; Prom v0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Prom
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../src/prom.html">prom package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../src/prom.conformity_scores.html">prom.conformity_scores package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../src/prom.control_risk.html">prom.control_risk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../src/prom.estimator.html">prom.estimator package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../src/prom.regression.html">prom.regression package</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Thread Coarsening API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/thread/Deeptune_utils.html">Deeptune_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/thread/Magni_utils.html">Magni_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/thread/Thread_Deep.html">Thread_Deep module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/thread/Thread_magni.html">Thread_magni module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Loop Tiling API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Deeptune_utils.html">Deeptune_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Loop_de.html">Loop_de module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Loop_ma.html">Loop_ma module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Loop_SVM.html">Loop_SVM module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Loop_thread_sensitive.html">Loop_thread_sensitive module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Magni_utils.html">Magni_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/Ml_utils.html">Ml_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/Loop/prom_util_sensitive.html">prom_util_sensitive module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Device Mapping API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.datasets.html">compy.datasets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.graphs.html">compy.models.graphs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.graphs.tf.cell.html">compy.models.graphs.tf.cell package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.graphs.tf.layer.html">compy.models.graphs.tf.layer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.graphs.tf.html">compy.models.graphs.tf package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.html">compy.models package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.models.seqs.html">compy.models.seqs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.representations.extractors.html">compy.representations.extractors package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/compy.representations.html">compy.representations package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/copy_pytorch_geom_model_sec.html">copy_pytorch_geom_model_sec module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/DevM_i2v.html">DevM_i2v module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/DevM_Programl.html">DevM_Programl module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/devmap_exploration.html">devmap_exploration module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/pytorch_geom_model_pchange.html">pytorch_geom_model_pchange module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/DeviceM/setup.html">setup module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Bug Detection API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/BugD/model.html">model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/BugD/preprocess.html">preprocess module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/BugD/VD_codebert.html">VD_codebert module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/BugD/VD_vulde.html">VD_vulde module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tensor Tuning API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/bert_large.html">bert_large module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/bert_med.html">bert_med module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/bert_tiny.html">bert_tiny module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/modules.html">scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/mtl_tlp_make_dataset.html">mtl_tlp_make_dataset module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/mtl_tlp_train.html">mtl_tlp_train module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/sensitive.html">sensitive module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/tlp_fine_tune.html">tlp_fine_tune module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../case_study/tlp/train_tlp.html">train_tlp module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Prom</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">prom.estimator.estimator</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for prom.estimator.estimator</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">BaseCrossValidator</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">_safe_indexing</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">_num_samples</span><span class="p">,</span> <span class="n">check_is_fitted</span>

<span class="kn">from</span> <span class="nn">src.prom._typing</span> <span class="kn">import</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">NDArray</span>
<span class="kn">from</span> <span class="nn">src.prom.aggregation_functions</span> <span class="kn">import</span> <span class="n">aggregate_all</span><span class="p">,</span> <span class="n">phi2D</span>
<span class="kn">from</span> <span class="nn">src.prom.estimator.interface</span> <span class="kn">import</span> <span class="n">EnsembleEstimator</span>
<span class="kn">from</span> <span class="nn">src.prom.utils</span> <span class="kn">import</span> <span class="p">(</span><span class="n">check_nan_in_aposteriori_prediction</span><span class="p">,</span> <span class="n">check_no_agg_cv</span><span class="p">,</span>
                         <span class="n">fit_estimator</span><span class="p">)</span>


<div class="viewcode-block" id="EnsembleRegressor"><a class="viewcode-back" href="../../../src/prom.estimator.html#prom.estimator.estimator.EnsembleRegressor">[docs]</a><span class="k">class</span> <span class="nc">EnsembleRegressor</span><span class="p">(</span><span class="n">EnsembleEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class implements methods to handle the training and usage of the</span>
<span class="sd">    estimator. This estimator can be unique or composed by cross validated</span>
<span class="sd">    estimators.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator: Optional[RegressorMixin]</span>
<span class="sd">        Any regressor with scikit-learn API</span>
<span class="sd">        (i.e. with ``fit`` and ``predict`` methods).</span>
<span class="sd">        If ``None``, estimator defaults to a ``LinearRegression`` instance.</span>

<span class="sd">        By default ``None``.</span>

<span class="sd">    method: str</span>
<span class="sd">        Method to choose for prediction interval estimates.</span>
<span class="sd">        Choose among:</span>

<span class="sd">        - ``&quot;naive&quot;``, based on training set conformity scores,</span>
<span class="sd">        - ``&quot;base&quot;``, based on validation sets conformity scores,</span>
<span class="sd">        - ``&quot;plus&quot;``, based on validation conformity scores and</span>
<span class="sd">          testing predictions,</span>
<span class="sd">        - ``&quot;minmax&quot;``, based on validation conformity scores and</span>
<span class="sd">          testing predictions (min/max among cross-validation clones).</span>

<span class="sd">        By default ``&quot;plus&quot;``.</span>

<span class="sd">    cv: Optional[Union[int, str, BaseCrossValidator]]</span>
<span class="sd">        The cross-validation strategy for computing conformity scores.</span>
<span class="sd">        It directly drives the distinction between jackknife and cv variants.</span>
<span class="sd">        Choose among:</span>

<span class="sd">        - ``None``, to use the default 5-fold cross-validation</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">          If equal to ``-1``, equivalent to</span>
<span class="sd">          ``sklearn.model_selection.LeaveOneOut()``.</span>
<span class="sd">        - CV splitter: any ``sklearn.model_selection.BaseCrossValidator``</span>
<span class="sd">          Main variants are:</span>
<span class="sd">            - ``sklearn.model_selection.LeaveOneOut`` (jackknife),</span>
<span class="sd">            - ``sklearn.model_selection.KFold`` (cross-validation),</span>
<span class="sd">            - ``subsample.Subsample`` object (bootstrap).</span>
<span class="sd">        - ``&quot;split&quot;``, does not involve cross-validation but a division</span>
<span class="sd">          of the data into training and calibration subsets. The splitter</span>
<span class="sd">          used is the following: ``sklearn.model_selection.ShuffleSplit``.</span>
<span class="sd">        - ``&quot;prefit&quot;``, assumes that ``estimator`` has been fitted already,</span>
<span class="sd">          and the ``method`` parameter is ignored.</span>
<span class="sd">          All data provided in the ``fit`` method is then used</span>
<span class="sd">          for computing conformity scores only.</span>
<span class="sd">          At prediction time, quantiles of these conformity scores are used</span>
<span class="sd">          to provide a prediction interval with fixed width.</span>
<span class="sd">          The user has to take care manually that data for model fitting and</span>
<span class="sd">          conformity scores estimate are disjoint.</span>

<span class="sd">        By default ``None``.</span>

<span class="sd">    test_size: Optional[Union[int, float]]</span>
<span class="sd">        If ``float``, should be between ``0.0`` and ``1.0`` and represent the</span>
<span class="sd">        proportion of the dataset to include in the test split. If ``int``,</span>
<span class="sd">        represents the absolute number of test samples. If ``None``,</span>
<span class="sd">        it will be set to ``0.1``.</span>

<span class="sd">        If cv is not ``&quot;split&quot;``, ``test_size`` is ignored.</span>

<span class="sd">        By default ``None``.</span>

<span class="sd">    n_jobs: Optional[int]</span>
<span class="sd">        Number of jobs for parallel processing using joblib</span>
<span class="sd">        via the &quot;locky&quot; backend.</span>
<span class="sd">        If ``-1`` all CPUs are used.</span>
<span class="sd">        If ``1`` is given, no parallel computing code is used at all,</span>
<span class="sd">        which is useful for debugging.</span>
<span class="sd">        For ``n_jobs`` below ``-1``, ``(n_cpus + 1 - n_jobs)`` are used.</span>
<span class="sd">        ``None`` is a marker for `unset` that will be interpreted as</span>
<span class="sd">        ``n_jobs=1`` (sequential execution).</span>

<span class="sd">        By default ``None``.</span>

<span class="sd">    agg_function: Optional[str]</span>
<span class="sd">        Determines how to aggregate predictions from perturbed models, both at</span>
<span class="sd">        training and prediction time.</span>

<span class="sd">        If ``None``, it is ignored except if ``cv`` class is ``Subsample``,</span>
<span class="sd">        in which case an error is raised.</span>
<span class="sd">        If ``&quot;mean&quot;`` or ``&quot;median&quot;``, returns the mean or median of the</span>
<span class="sd">        predictions computed from the out-of-folds models.</span>
<span class="sd">        Note: if you plan to set the ``ensemble`` argument to ``True`` in the</span>
<span class="sd">        ``predict`` method, you have to specify an aggregation function.</span>
<span class="sd">        Otherwise an error would be raised.</span>

<span class="sd">        The Jackknife+ interval can be interpreted as an interval around the</span>
<span class="sd">        median prediction, and is guaranteed to lie inside the interval,</span>
<span class="sd">        unlike the single estimator predictions.</span>

<span class="sd">        When the cross-validation strategy is ``Subsample`` (i.e. for the</span>
<span class="sd">        Jackknife+-after-Bootstrap method), this function is also used to</span>
<span class="sd">        aggregate the training set in-sample predictions.</span>

<span class="sd">        If ``cv`` is ``&quot;prefit&quot;`` or ``&quot;split&quot;``, ``agg_function`` is ignored.</span>

<span class="sd">        By default ``&quot;mean&quot;``.</span>

<span class="sd">    verbose: int</span>
<span class="sd">        The verbosity level, used with joblib for multiprocessing.</span>
<span class="sd">        The frequency of the messages increases with the verbosity level.</span>
<span class="sd">        If it more than ``10``, all iterations are reported.</span>
<span class="sd">        Above ``50``, the output is sent to stdout.</span>

<span class="sd">        By default ``0``.</span>

<span class="sd">    random_state: Optional[Union[int, RandomState]]</span>
<span class="sd">        Pseudo random number generator state used for random sampling.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>

<span class="sd">        By default ``None``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    single_estimator_: sklearn.RegressorMixin</span>
<span class="sd">        Estimator fitted on the whole training set.</span>

<span class="sd">    estimators_: list</span>
<span class="sd">        List of out-of-folds estimators.</span>

<span class="sd">    k_: ArrayLike</span>
<span class="sd">        - Array of nans, of shape (len(y), 1) if ``cv`` is ``&quot;prefit&quot;``</span>
<span class="sd">          (defined but not used)</span>
<span class="sd">        - Dummy array of folds containing each training sample, otherwise.</span>
<span class="sd">          Of shape (n_samples_train, cv.get_n_splits(X_train, y_train)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">no_agg_cv_</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;prefit&quot;</span><span class="p">,</span> <span class="s2">&quot;split&quot;</span><span class="p">]</span>
    <span class="n">no_agg_methods_</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;naive&quot;</span><span class="p">,</span> <span class="s2">&quot;base&quot;</span><span class="p">]</span>
    <span class="n">fit_attributes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;single_estimator_&quot;</span><span class="p">,</span>
        <span class="s2">&quot;estimators_&quot;</span><span class="p">,</span>
        <span class="s2">&quot;k_&quot;</span><span class="p">,</span>
        <span class="s2">&quot;use_split_method_&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RegressorMixin</span><span class="p">],</span>
        <span class="n">method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">BaseCrossValidator</span><span class="p">]],</span>
        <span class="n">agg_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">]],</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agg_function</span> <span class="o">=</span> <span class="n">agg_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_fit_oof_estimator</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="n">RegressorMixin</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">train_index</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">fit_params</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RegressorMixin</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit a single out-of-fold model on a given training set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        estimator: RegressorMixin</span>
<span class="sd">            Estimator to train.</span>

<span class="sd">        X: ArrayLike of shape (n_samples, n_features)</span>
<span class="sd">            Input data.</span>

<span class="sd">        y: ArrayLike of shape (n_samples,)</span>
<span class="sd">            Input labels.</span>

<span class="sd">        train_index: ArrayLike of shape (n_samples_train)</span>
<span class="sd">            Training data indices.</span>

<span class="sd">        sample_weight: Optional[ArrayLike] of shape (n_samples,)</span>
<span class="sd">            Sample weights. If None, then samples are equally weighted.</span>
<span class="sd">            By default ``None``.</span>

<span class="sd">        **fit_params : dict</span>
<span class="sd">            Additional fit parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        RegressorMixin</span>
<span class="sd">            Fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">train_index</span><span class="p">)</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">train_index</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">train_index</span><span class="p">)</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

        <span class="n">estimator</span> <span class="o">=</span> <span class="n">fit_estimator</span><span class="p">(</span>
            <span class="n">estimator</span><span class="p">,</span>
            <span class="n">X_train</span><span class="p">,</span>
            <span class="n">y_train</span><span class="p">,</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
            <span class="o">**</span><span class="n">fit_params</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">estimator</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_predict_oof_estimator</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="n">RegressorMixin</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">val_index</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform predictions on a single out-of-fold model on a validation set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        estimator: RegressorMixin</span>
<span class="sd">            Estimator to train.</span>

<span class="sd">        X: ArrayLike of shape (n_samples, n_features)</span>
<span class="sd">            Input data.</span>

<span class="sd">        val_index: ArrayLike of shape (n_samples_val)</span>
<span class="sd">            Validation data indices.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[NDArray, ArrayLike]</span>
<span class="sd">            Predictions of estimator from val_index of X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_val</span> <span class="o">=</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">val_index</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
        <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">val_index</span>

    <span class="k">def</span> <span class="nf">_aggregate_with_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">NDArray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Take the array of predictions, made by the refitted estimators,</span>
<span class="sd">        on the testing set, and the 1-or-nan array indicating for each training</span>
<span class="sd">        sample which one to integrate, and aggregate to produce phi-{t}(x_t)</span>
<span class="sd">        for each training sample x_t.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x: ArrayLike of shape (n_samples_test, n_estimators)</span>
<span class="sd">            Array of predictions, made by the refitted estimators,</span>
<span class="sd">            for each sample of the testing set.</span>

<span class="sd">        k: ArrayLike of shape (n_samples_training, n_estimators)</span>
<span class="sd">            1-or-nan array: indicates whether to integrate the prediction</span>
<span class="sd">            of a given estimator into the aggregation, for each training</span>
<span class="sd">            sample.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ArrayLike of shape (n_samples_test,)</span>
<span class="sd">            Array of aggregated predictions for each testing sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_agg_methods_</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_split_method_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;There should not be aggregation of predictions &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;if cv is in &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">no_agg_cv_</span><span class="si">}</span><span class="s2">&#39;, if cv &gt;=2 &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or if method is in &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">no_agg_methods_</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">agg_function</span> <span class="o">==</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">phi2D</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmedian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># To aggregate with mean() the aggregation coud be done</span>
        <span class="c1"># with phi2D(A=x, B=k, fun=lambda x: np.nanmean(x, axis=1).</span>
        <span class="c1"># However, phi2D contains a np.apply_along_axis loop which</span>
        <span class="c1"># is much slower than the matrices multiplication that can</span>
        <span class="c1"># be used to compute the means.</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">agg_function</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">K</span> <span class="o">/</span> <span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The value of self.agg_function is not correct&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pred_multi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a prediction per train sample for each test sample, by</span>
<span class="sd">        aggregation with matrix ``k_``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: ArrayLike of shape (n_samples_test, n_features)</span>
<span class="sd">            Input data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        NDArray of shape (n_samples_test, n_samples_train)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_pred_multi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># At this point, y_pred_multi is of shape</span>
        <span class="c1"># (n_samples_test, n_estimators_). The method</span>
        <span class="c1"># ``_aggregate_with_mask`` fits it to the right size</span>
        <span class="c1"># thanks to the shape of k_.</span>
        <span class="n">y_pred_multi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_with_mask</span><span class="p">(</span><span class="n">y_pred_multi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_pred_multi</span>

<div class="viewcode-block" id="EnsembleRegressor.predict_calib"><a class="viewcode-back" href="../../../src/prom.estimator.html#prom.estimator.estimator.EnsembleRegressor.predict_calib">[docs]</a>    <span class="k">def</span> <span class="nf">predict_calib</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform predictions on X : the calibration set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: ArrayLike of shape (n_samples_test, n_features)</span>
<span class="sd">            Input data</span>

<span class="sd">        y: Optional[ArrayLike] of shape (n_samples_test,)</span>
<span class="sd">            Input labels.</span>

<span class="sd">            By default ``None``.</span>

<span class="sd">        groups: Optional[ArrayLike] of shape (n_samples_test,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">            By default ``None``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        NDArray of shape (n_samples_test, 1)</span>
<span class="sd">            The predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_attributes</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="s2">&quot;prefit&quot;</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;naive&quot;</span><span class="p">:</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cv</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">)</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)(</span>
                    <span class="n">delayed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_predict_oof_estimator</span><span class="p">)(</span>
                        <span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">calib_index</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">calib_index</span><span class="p">),</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                        <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">predictions</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="n">pred_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)),</span>
                    <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
                    <span class="n">pred_matrix</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                        <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">k_</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">check_nan_in_aposteriori_prediction</span><span class="p">(</span><span class="n">pred_matrix</span><span class="p">)</span>

                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">aggregate_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agg_function</span><span class="p">,</span> <span class="n">pred_matrix</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">y_pred</span></div>

<div class="viewcode-block" id="EnsembleRegressor.fit"><a class="viewcode-back" href="../../../src/prom.estimator.html#prom.estimator.estimator.EnsembleRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">fit_params</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EnsembleRegressor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the base estimator under the ``single_estimator_`` attribute.</span>
<span class="sd">        Fit all cross-validated estimator clones</span>
<span class="sd">        and rearrange them into a list, the ``estimators_`` attribute.</span>
<span class="sd">        Out-of-fold conformity scores are stored under</span>
<span class="sd">        the ``conformity_scores_`` attribute.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: ArrayLike of shape (n_samples, n_features)</span>
<span class="sd">            Input data.</span>

<span class="sd">        y: ArrayLike of shape (n_samples,)</span>
<span class="sd">            Input labels.</span>

<span class="sd">        sample_weight: Optional[ArrayLike] of shape (n_samples,)</span>
<span class="sd">            Sample weights. If None, then samples are equally weighted.</span>

<span class="sd">            By default ``None``.</span>

<span class="sd">        groups: Optional[ArrayLike] of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">            By default ``None``.</span>

<span class="sd">        **fit_params : dict</span>
<span class="sd">            Additional fit parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        EnsembleRegressor</span>
<span class="sd">            The estimator fitted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialization</span>
        <span class="n">single_estimator_</span><span class="p">:</span> <span class="n">RegressorMixin</span>
        <span class="n">estimators_</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">RegressorMixin</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">full_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_split_method_</span> <span class="o">=</span> <span class="n">check_no_agg_cv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_agg_cv_</span><span class="p">)</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Computation</span>
        <span class="k">if</span> <span class="n">cv</span> <span class="o">==</span> <span class="s2">&quot;prefit&quot;</span><span class="p">:</span>
            <span class="n">single_estimator_</span> <span class="o">=</span> <span class="n">estimator</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">single_estimator_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_oof_estimator</span><span class="p">(</span>
                <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">full_indexes</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="o">**</span><span class="n">fit_params</span>
            <span class="p">)</span>
            <span class="n">cv</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">,</span> <span class="n">cv</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">k_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)),</span>
                <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;naive&quot;</span><span class="p">:</span>
                <span class="n">estimators_</span> <span class="o">=</span> <span class="p">[</span><span class="n">single_estimator_</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">estimators_</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)(</span>
                    <span class="n">delayed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fit_oof_estimator</span><span class="p">)(</span>
                        <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
                        <span class="n">X</span><span class="p">,</span>
                        <span class="n">y</span><span class="p">,</span>
                        <span class="n">train_index</span><span class="p">,</span>
                        <span class="n">sample_weight</span><span class="p">,</span>
                        <span class="o">**</span><span class="n">fit_params</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># In split-CP, we keep only the model fitted on train dataset</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_split_method_</span><span class="p">:</span>
                    <span class="n">single_estimator_</span> <span class="o">=</span> <span class="n">estimators_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">single_estimator_</span> <span class="o">=</span> <span class="n">single_estimator_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">estimators_</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="EnsembleRegressor.predict"><a class="viewcode-back" href="../../../src/prom.estimator.html#prom.estimator.estimator.EnsembleRegressor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">ensemble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_multi_pred</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict target from X. It also computes the prediction per train sample</span>
<span class="sd">        for each test sample according to ``self.method``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: ArrayLike of shape (n_samples, n_features)</span>
<span class="sd">            Test data.</span>

<span class="sd">        ensemble: bool</span>
<span class="sd">            Boolean determining whether the predictions are ensembled or not.</span>
<span class="sd">            If ``False``, predictions are those of the model trained on the</span>
<span class="sd">            whole training set.</span>
<span class="sd">            If ``True``, predictions from perturbed models are aggregated by</span>
<span class="sd">            the aggregation function specified in the ``agg_function``</span>
<span class="sd">            attribute.</span>

<span class="sd">            If ``cv`` is ``&quot;prefit&quot;`` or ``&quot;split&quot;``, ``ensemble`` is ignored.</span>

<span class="sd">            By default ``False``.</span>

<span class="sd">        return_multi_pred: bool</span>
<span class="sd">            If ``True`` the method returns the predictions and the multiple</span>
<span class="sd">            predictions (3 arrays). If ``False`` the method return the</span>
<span class="sd">            simple predictions only.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[NDArray, NDArray, NDArray]</span>
<span class="sd">            - Predictions</span>
<span class="sd">            - The multiple predictions for the lower bound of the intervals.</span>
<span class="sd">            - The multiple predictions for the upper bound of the intervals.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_attributes</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">single_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_multi_pred</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ensemble</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_pred</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_agg_methods_</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_split_method_</span><span class="p">:</span>
            <span class="n">y_pred_multi_low</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="n">y_pred_multi_up</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_pred_multi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pred_multi</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;minmax&quot;</span><span class="p">:</span>
                <span class="n">y_pred_multi_low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_pred_multi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">y_pred_multi_up</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_pred_multi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;plus&quot;</span><span class="p">:</span>
                <span class="n">y_pred_multi_low</span> <span class="o">=</span> <span class="n">y_pred_multi</span>
                <span class="n">y_pred_multi_up</span> <span class="o">=</span> <span class="n">y_pred_multi</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred_multi_low</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                <span class="n">y_pred_multi_up</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">ensemble</span><span class="p">:</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">aggregate_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agg_function</span><span class="p">,</span> <span class="n">y_pred_multi</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_multi_pred</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_pred_multi_low</span><span class="p">,</span> <span class="n">y_pred_multi_up</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_pred</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, _.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>